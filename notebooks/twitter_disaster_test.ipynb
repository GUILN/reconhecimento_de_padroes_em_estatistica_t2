{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Disaster Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "\n",
    "DATASET_FOLDER = \"../data/nlp-getting-started\"\n",
    "TRAIN_FILE = path.join(DATASET_FOLDER, \"train.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_tweets = pd.read_csv(TRAIN_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df_tweets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data cleaning\n",
    "'''\n",
    "def data_cleaning_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.keyword.fillna(\"\", inplace=True)\n",
    "    df.location.fillna(\"\", inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data preprocessing\n",
    "'''\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def encode_location(df: pd.DataFrame) -> None:\n",
    "    le = LabelEncoder()\n",
    "    df[\"location\"] = le.fit_transform(df[\"location\"])\n",
    "\n",
    "def data_preprocessing_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.text.apply(lambda x: x.lower())\n",
    "    df.keyword.apply(lambda x: x.lower())\n",
    "    df.location.apply(lambda x: x.lower())\n",
    "    encode_location(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/guilhermeleonardonunes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Data vectorization\n",
    "'''\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def data_vectorization_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_vec = df.copy()\n",
    "    stop_words = stopwords.words('english')\n",
    "    vectorizer = TfidfVectorizer(stop_words=stop_words, max_features=1000)\n",
    "    X = vectorizer.fit_transform(df_vec.text)\n",
    "    df_features = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    df_features[\"target\"] = df[\"target\"]\n",
    "    df_features[\"location\"] = df[\"location\"]\n",
    "        \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data preparation pipeline\n",
    "\n",
    "apply all the above pipelines\n",
    "'''\n",
    "def data_preparation_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = data_cleaning_pipeline(df)\n",
    "    display(df.target.isna().sum())\n",
    "    df = data_preprocessing_pipeline(df)\n",
    "    display(df.target.isna().sum())\n",
    "    df = data_vectorization_pipeline(df)\n",
    "    display(df.target.isna().sum())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_correlated_features(df: pd.DataFrame, correlation_value: float = 0.1) -> pd.Series:\n",
    "    # select most correlated features\n",
    "    df_corr = df.corr()\n",
    "    df_corr_target = df_corr[\"target\"].abs()\n",
    "    df_corr_target = df_corr[df_corr_target > correlation_value]\n",
    "    return df_corr_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1222"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare data for training\n",
    "df_train = data_preparation_pipeline(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
